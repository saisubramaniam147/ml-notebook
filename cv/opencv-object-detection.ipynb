{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple object detection using YOLOv2 and OpenCV\n",
    "#### Notebook opens webcam and captures each frame and passes to YOLO model to detect presence of any object trained using the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from darkflow.net.build import TFNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conert image data to TF Example proto\n",
    "def image_to_tfexample(image_data, image_format, height, width, class_id):\n",
    "  return tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/encoded': bytes_feature(image_data),\n",
    "      'image/format': bytes_feature(image_format),\n",
    "      'image/class/label': int64_feature(class_id),\n",
    "      'image/height': int64_feature(height),\n",
    "      'image/width': int64_feature(width),\n",
    "  }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\scripts\\tf-models\\tensorflow\\models\\research\\object_detection\\utils\\visualization_utils.py:25: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"c:\\program files\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\program files\\python36\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 281, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 232, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 397, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-42629e16abc1>\", line 1, in <module>\n",
      "    from matplotlib import pyplot as plt\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\matplotlib\\pyplot.py\", line 72, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def grabVideoFeed():\n",
    "    index, frame = cap.read()\n",
    "    return frame if index else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialSetup():\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "    # Unpersist graph from file\n",
    "    with tf.gfile.FastGFile('tensorflow_inception_graph.pb', 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "initialSetup()\n",
    "\n",
    "# to print all nodes of graph\n",
    "#print([n.name for n in tf.get_default_graph().as_graph_def().node])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "https://github.com/tensorflow/models/tree/master/research/slim\n",
    "\n",
    "https://towardsdatascience.com/building-a-real-time-object-recognition-app-with-tensorflow-and-opencv-b7a2b4ebdc32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\darkflow\\dark\\darknet.py:54: UserWarning: ./cfg/yolo.cfg not found, use D:/scripts/darkflow-master/cfg/yolo.cfg instead\n",
      "  cfg_path, FLAGS.model))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing D:/scripts/darkflow-master/cfg/yolo.cfg\n",
      "Loading D:/scripts/darkflow-master/cfg/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.07137560844421387s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 1.0 usage\n",
      "Finished in 18.424335956573486s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained YOLO model (coco dataset) to detect common objects.\n",
    "\n",
    "#windows\n",
    "options = {\"model\": \"D:/scripts/darkflow-master/cfg/yolo.cfg\", \"load\": \"D:/scripts/darkflow-master/cfg/yolo.weights\", \"threshold\": 0.5, \"gpu\": 1.0}\n",
    "\n",
    "\n",
    "#ubuntu\n",
    "#options = {\"model\": \"/media/sf_scripts/darkflow-master/cfg/yolo.cfg\", \"load\": \"/media/sf_scripts/darkflow-master/cfg/yolo.weights\", \"threshold\": 0.5}\n",
    "\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'person', 'confidence': 0.71099794, 'topleft': {'x': 33, 'y': 154}, 'bottomright': {'x': 541, 'y': 477}}]\n",
      "[{'label': 'person', 'confidence': 0.78867757, 'topleft': {'x': 89, 'y': 116}, 'bottomright': {'x': 614, 'y': 474}}]\n",
      "[{'label': 'person', 'confidence': 0.77109385, 'topleft': {'x': 71, 'y': 122}, 'bottomright': {'x': 500, 'y': 468}}]\n",
      "[{'label': 'person', 'confidence': 0.81680351, 'topleft': {'x': 48, 'y': 120}, 'bottomright': {'x': 463, 'y': 471}}]\n",
      "[{'label': 'person', 'confidence': 0.7676301, 'topleft': {'x': 68, 'y': 120}, 'bottomright': {'x': 499, 'y': 466}}]\n",
      "[{'label': 'person', 'confidence': 0.80965489, 'topleft': {'x': 60, 'y': 126}, 'bottomright': {'x': 511, 'y': 462}}]\n",
      "[{'label': 'person', 'confidence': 0.79530334, 'topleft': {'x': 65, 'y': 128}, 'bottomright': {'x': 508, 'y': 459}}]\n",
      "[{'label': 'person', 'confidence': 0.85722095, 'topleft': {'x': 71, 'y': 113}, 'bottomright': {'x': 511, 'y': 474}}]\n",
      "[{'label': 'person', 'confidence': 0.82554942, 'topleft': {'x': 52, 'y': 106}, 'bottomright': {'x': 514, 'y': 471}}]\n",
      "[{'label': 'person', 'confidence': 0.90028095, 'topleft': {'x': 8, 'y': 96}, 'bottomright': {'x': 435, 'y': 479}}]\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    frame = grabVideoFeed()\n",
    "    if frame is None:\n",
    "        raise SystemError('ERROR: Cannot receive video frame')\n",
    "\n",
    "    cv2.imshow('Main', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    result = tfnet.return_predict(frame)\n",
    "    print(result)\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'tvmonitor', 'confidence': 0.124221556, 'topleft': {'x': 323, 'y': 147}, 'bottomright': {'x': 409, 'y': 313}}, {'label': 'cup', 'confidence': 0.458379, 'topleft': {'x': 318, 'y': 145}, 'bottomright': {'x': 423, 'y': 317}}, {'label': 'cup', 'confidence': 0.3655611, 'topleft': {'x': 374, 'y': 346}, 'bottomright': {'x': 421, 'y': 374}}, {'label': 'spoon', 'confidence': 0.12179081, 'topleft': {'x': 464, 'y': 259}, 'bottomright': {'x': 499, 'y': 357}}, {'label': 'bowl', 'confidence': 0.24720773, 'topleft': {'x': 419, 'y': 316}, 'bottomright': {'x': 484, 'y': 364}}, {'label': 'tvmonitor', 'confidence': 0.88161147, 'topleft': {'x': 157, 'y': 94}, 'bottomright': {'x': 345, 'y': 280}}, {'label': 'keyboard', 'confidence': 0.79866266, 'topleft': {'x': 123, 'y': 263}, 'bottomright': {'x': 333, 'y': 371}}, {'label': 'refrigerator', 'confidence': 0.487068, 'topleft': {'x': 0, 'y': 19}, 'bottomright': {'x': 130, 'y': 351}}]\n"
     ]
    }
   ],
   "source": [
    "# sample image snapshot\n",
    "imgcv = cv2.imread(\"/media/sf_scripts/darkflow-master/sample_img/sample_computer.jpg\")\n",
    "result = tfnet.return_predict(imgcv)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
